# Define the GPU architecture based on the NVIDIA GPU model
TORCH_CUDA_ARCH_LIST=7.5
# Check the NVIDIA CUDA GPUs page to find the version for your card: https://developer.nvidia.com/cuda-gpus

# Set the CLI arguments for the model, precision, and devices
CLI_ARGS=--model llama-7b-4bit --wbits 4 --listen --auto-devices

# Example commands with different configurations
# Example running 13b with 4bit/128 groupsize: CLI_ARGS=--model llama-1
